{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1659da5e-37ac-4a8d-9af0-c4837274c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesbeat.result import get_fit\n",
    "from bayesbeat.data import get_data, get_n_entries\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from utils import (\n",
    "    get_duration,\n",
    "    get_frequency,\n",
    "    compute_residuals,\n",
    "    model_colours,\n",
    "    model_labels,\n",
    ")\n",
    "\n",
    "plt.style.use(\"paper.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76638f9-eab5-4028-88fe-de1506782677",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = pathlib.Path(\"figures\") / \"real_data\"\n",
    "outdir.mkdir(exist_ok=True)\n",
    "\n",
    "file_format = \"pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfac706-6721-40e0-a549-26ce4bac2abf",
   "metadata": {},
   "source": [
    "Path to the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd9971-2e15-471b-9017-1e95f5bfd604",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../data/PyTotalAnalysis_2024_02_23.mat\"\n",
    "n_ringdowns = get_n_entries(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada6418e",
   "metadata": {},
   "source": [
    "Path to result files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3930ee-56ef-4b12-9d4a-5d28981e58bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    \"model_1_constant_noise\": pathlib.Path(\"../analysis/gens_data/rundir/model_1_constant_noise/\"),\n",
    "    \"model_1\": pathlib.Path(\"../analysis/gens_data/rundir/model_1/\"),\n",
    "    \"model_3\": pathlib.Path(\"../analysis/gens_data/rundir/model_3_7_terms\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95fb2ae-233d-4083-bed6-635874123d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_z = {}\n",
    "for key, path in paths.items():\n",
    "    log_z[key] = np.empty(n_ringdowns)\n",
    "    for index in range(n_ringdowns):\n",
    "        result_file=path / \"analysis\" / f\"index_{index}\" / \"result.hdf5\"\n",
    "        try:\n",
    "            with h5py.File(result_file, \"r\") as res_file:\n",
    "                log_z[key][index] = res_file[\"log_evidence\"][()]\n",
    "        except OSError:\n",
    "            log_z[key][index] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ddef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "injections = [0, 4, 43]\n",
    "for inj in injections:\n",
    "    print(f\"log10 BF (1 vs 1 (stationary)) - {inj}: {(log_z['model_1'][inj] - log_z['model_1_constant_noise'][inj]) / np.log(10)}\")\n",
    "    print(f\"log10 BF (3 vs 1 (same noise)) - {inj}: {(log_z['model_3'][inj] - log_z['model_1'][inj]) / np.log(10)}\")\n",
    "    print(f\"log10 BF (3 vs 1 (stationary)) - {inj}: {(log_z['model_3'][inj] - log_z['model_1_constant_noise'][inj]) / np.log(10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d694c96-85c9-4ea7-afa8-932ea1f4d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {}\n",
    "for key, path in paths.items():\n",
    "    d = dict(\n",
    "        a_1=np.nan * np.empty(n_ringdowns),\n",
    "        a_ratio=np.nan * np.empty(n_ringdowns),\n",
    "        a_scale=np.nan * np.empty(n_ringdowns),\n",
    "        log10_a_1=np.nan * np.empty(n_ringdowns),\n",
    "        log10_a_scale=np.nan * np.empty(n_ringdowns),\n",
    "    )\n",
    "    for index in range(n_ringdowns):\n",
    "        result_file = path / \"analysis\" / f\"index_{index}\" / \"result.hdf5\"\n",
    "        try:\n",
    "            with h5py.File(result_file, \"r\") as res_file:\n",
    "                posterior_samples = res_file[\"posterior_samples\"][()]\n",
    "            max_logl_idx = np.argmax(posterior_samples[\"logL\"])\n",
    "            for p in posterior_samples.dtype.names:\n",
    "                if p not in d:\n",
    "                    d[p] = np.empty(n_ringdowns)\n",
    "                d[p][index] = posterior_samples[p][max_logl_idx]\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "    for k in d.keys():\n",
    "        if k.startswith(\"log10\"):\n",
    "            new_key = k.lstrip(\"log10_\")\n",
    "            d[new_key] = 10 ** d[k]\n",
    "    parameters[key] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea6d17c-5be3-4031-8210-62e905ac6770",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = np.empty(n_ringdowns)\n",
    "for index in range(n_ringdowns):\n",
    "    durations[index] = get_duration(data_file, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4593c9-63f5-4df7-8ab7-79e6a69c1a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.empty(n_ringdowns)\n",
    "for index in range(n_ringdowns):\n",
    "    freqs[index] = get_frequency(data_file, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc62159e",
   "metadata": {},
   "source": [
    "## Figures 11, B3, B4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1007e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [0, 4, 43]\n",
    "\n",
    "for index in indices:\n",
    "\n",
    "    x_data, y_data, frequency, _ = get_data(data_file, index=index)\n",
    "    results = {}\n",
    "    for key, path in paths.items():\n",
    "        d = dict()\n",
    "        result_file = path / \"analysis\" / f\"index_{index}\" / \"result.hdf5\"\n",
    "        with h5py.File(result_file, \"r\") as res_file:\n",
    "            posterior_samples = res_file[\"posterior_samples\"][()]\n",
    "            d[\"log_z\"] = res_file[\"log_evidence\"][()]\n",
    "        # Get sample with max. log-likelihood\n",
    "        max_logl_idx = np.argmax(posterior_samples[\"logL\"])\n",
    "        # Get noise sigmas\n",
    "        \n",
    "        d[\"sigma_constant\"] = posterior_samples[\"sigma_constant_noise\"][max_logl_idx]\n",
    "        d[\"sigma_amp\"] = (\n",
    "            posterior_samples[\"sigma_amp_noise\"][max_logl_idx]\n",
    "            if \"sigma_amp_noise\" in posterior_samples.dtype.names else 0\n",
    "        )\n",
    "        d[\"y_fit\"] = get_fit(\n",
    "            config_file=next(path.glob(\"*.ini\")),\n",
    "            result_file=result_file,\n",
    "            datafile=data_file,\n",
    "            index=index,\n",
    "            method=\"max\",\n",
    "            compile=False,   # Avoid compiling the model for a single call\n",
    "        )\n",
    "        results[key] = d\n",
    "    dt = (x_data[1] - x_data[0])\n",
    "    sample_rate = 1 / dt\n",
    "    window = 150\n",
    "    window_duration = window * dt\n",
    "\n",
    "    figsize = plt.rcParams[\"figure.figsize\"].copy()\n",
    "    figsize[0] = 1.8 * figsize[0]\n",
    "    figsize[1] = 1.6 * figsize[1]\n",
    "    fig, axs = plt.subplot_mosaic(\n",
    "        [\n",
    "            [\"fit\", \"fit\", \"fit\", \"fit\"],\n",
    "            [\"fit\", \"fit\", \"fit\", \"fit\"],\n",
    "            [\"res\", \"res\", \"res\", \"res\"],\n",
    "            [\"mean\", \"mean\", \"mean\", \"mean\"],\n",
    "            [\"std\", \"std\", \"std\", \"std\"],\n",
    "        ],\n",
    "        figsize=figsize,\n",
    "    )\n",
    "\n",
    "\n",
    "    axs[\"fit\"].scatter(x_data, y_data, color=\"k\", s=1, label=\"Data\", rasterized=True)\n",
    "\n",
    "    for i, (key, res) in enumerate(results.items()):\n",
    "        y_fit = res[\"y_fit\"]\n",
    "        sigma_constant_noise = res[\"sigma_constant\"]\n",
    "        sigma_amp_noise = res[\"sigma_amp\"]\n",
    "        ln_evidence = res[\"log_z\"]\n",
    "        colour = f\"C{i}\"\n",
    "\n",
    "        axs[\"fit\"].plot(x_data, y_fit, c=colour, label=model_labels[key])\n",
    "        axs[\"fit\"].set_yscale(\"log\")\n",
    "        # axs[\"fit\"].legend()\n",
    "\n",
    "        residuals = compute_residuals(\n",
    "            y_data,\n",
    "            y_fit,\n",
    "            sigma_constant_noise=sigma_constant_noise,\n",
    "            sigma_amp_noise=sigma_amp_noise,\n",
    "        )\n",
    "        \n",
    "        axs[\"res\"].scatter(x_data, residuals, s=1, c=colour, lw=0.0, label=model_labels[key], rasterized=True)\n",
    "        # axs[\"res\"].plot(x_data, rolling_std(residuals, 500), c=colour)\n",
    "\n",
    "        res = pd.Series(residuals)\n",
    "        axs[\"mean\"].plot(x_data, res.rolling(window).mean().values, c=colour)\n",
    "        axs[\"mean\"].axhline(0.0, c=\"k\")\n",
    "        axs[\"std\"].plot(x_data, res.rolling(window).std().values, c=colour)\n",
    "        axs[\"std\"].axhline(1.0, c=\"k\")\n",
    "\n",
    "    axs[\"std\"].set_xlabel(\"Time [s]\")\n",
    "    axs[\"fit\"].set_ylabel(\"Scaled amplitude\")\n",
    "    axs[\"res\"].set_ylabel(r\"$\\mathcal{R}$\")\n",
    "\n",
    "    axs[\"mean\"].set_ylabel(r\"$\\mu_\\mathcal{R}$\")\n",
    "    axs[\"std\"].set_ylabel(r\"$\\sigma_{\\mathcal{R}}$\")\n",
    "\n",
    "    axs[\"fit\"].tick_params(labelbottom=False)\n",
    "    axs[\"res\"].tick_params(labelbottom=False)\n",
    "    axs[\"mean\"].tick_params(labelbottom=False)\n",
    "\n",
    "    axs[\"fit\"].sharex(axs[\"res\"])\n",
    "    axs[\"res\"].sharex(axs[\"mean\"])\n",
    "    axs[\"mean\"].sharex(axs[\"std\"])\n",
    "    axs[\"fit\"].set_xlim(0, x_data[-1])\n",
    "\n",
    "    # axs[\"res\"].set_ylim(0.5, 2.5)\n",
    "\n",
    "    # axs[\"fit\"].set_title(r\"$\\log_{10} \\mathcal{B}_{B/A} = \" + f\"{log10_bf[index]:.1f}\" + \"$\")\n",
    "\n",
    "    legend_handles = (\n",
    "        [Line2D([0], [0], ls=\"\", marker=\".\", label=\"Data\", color=\"k\")] \n",
    "        + [\n",
    "            Line2D([0], [0], color=model_colours[key], label=model_labels[key])\n",
    "            for key in results\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    fig.legend(\n",
    "        handles=legend_handles,\n",
    "        loc=\"center\",\n",
    "        ncol=4,\n",
    "        bbox_to_anchor=(0.5, -0.0)\n",
    "    )\n",
    "\n",
    "    subdir = outdir / \"fits\"\n",
    "    subdir.mkdir(parents=True, exist_ok=True)\n",
    "    fig.savefig(subdir / f\"fits_{index}_all_models.{file_format}\", bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee85427-2241-40e6-a3fc-9629a0d93715",
   "metadata": {},
   "source": [
    "## Bayes Factors - Figures 13, B3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4dcbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "\n",
    "from matplotlib.colors import SymLogNorm\n",
    "\n",
    "model_1 = \"model_1\"\n",
    "model_2 = \"model_1_constant_noise\"\n",
    "a_total = (parameters[model_1][\"a_1\"]) + parameters[model_1][\"a_ratio\"] * parameters[model_1][\"a_1\"]\n",
    "log10_bf_noise = (log_z[model_1] - log_z[model_2]) / np.log(10)\n",
    "\n",
    "tau_diff = parameters[model_1][\"tau_1\"] - parameters[model_1][\"tau_2\"]\n",
    "\n",
    "vabs = np.abs(tau_diff).max()\n",
    "\n",
    "norm = SymLogNorm(linthresh=1, linscale=1, vmin=-vabs, vmax=vabs, base=10)\n",
    "plt.scatter(a_total, log10_bf_noise, c=tau_diff, cmap=\"managua\", marker=\"o\", s=10, norm=norm)\n",
    "cbar = plt.colorbar(label=r\"$\\widehat{\\tau_1} - \\widehat{\\tau_2}$\")\n",
    "cbar.ax.set_yticks([-1e3, -1e1, 0, 1e1, 1e3])\n",
    "# plt.scatter(a_total, log10_bf, color=\"C0\")\n",
    "plt.title(r\"$M_1, \\xi_\\text{A} > 0$ vs. $M_1, \\xi_\\text{A} = 0$\")\n",
    "\n",
    "# axs.set_xscale(\"log\")\n",
    "axs.set_xlabel(r\"$\\widehat{a_\\text{T}}$\")\n",
    "axs.set_yscale(\"log\")\n",
    "# axs.set_yscale(\"symlog\")\n",
    "axs.set_ylabel(r\"$\\log_{10} \\mathcal{B}$\")\n",
    "\n",
    "fig.savefig(outdir / f\"bayes_factor_vs_a_total_simple_model.{file_format}\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752f873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "\n",
    "model_1 = \"model_3\"\n",
    "model_2 = \"model_1\"\n",
    "a_total = (parameters[model_1][\"a_1\"]) + parameters[model_1][\"a_ratio\"] * parameters[model_1][\"a_1\"]\n",
    "log10_bf_signal = (log_z[model_1] - log_z[model_2]) / np.log(10)\n",
    "\n",
    "tau_diff = parameters[model_1][\"tau_1\"] - parameters[model_1][\"tau_2\"]\n",
    "cval = tau_diff\n",
    "vabs = np.abs(cval).max()\n",
    "\n",
    "norm = SymLogNorm(linthresh=1, linscale=1, vmin=-vabs, vmax=vabs, base=10)\n",
    "plt.scatter(a_total, log10_bf_signal, c=cval, cmap=\"managua\", marker=\"o\", s=10, norm=norm)\n",
    "cbar = plt.colorbar(label=r\"$\\widehat{\\tau_1} - \\widehat{\\tau_2}$\")\n",
    "cbar.ax.set_yticks([-1e3, -1e1, 0, 1e1, 1e3])\n",
    "\n",
    "plt.title(r\"$M_3, T=7, \\xi_\\text{A} > 0$ vs. $M_1, \\xi_\\text{A} > 0$\")\n",
    "# axs.set_xscale(\"log\")\n",
    "axs.set_xlabel(r\"$\\widehat{a_\\text{T}}$\")\n",
    "# axs.set_yscale(\"log\")\n",
    "axs.set_yscale(\"symlog\")\n",
    "axs.set_ylabel(r\"$\\log_{10} \\mathcal{B}$\")\n",
    "fig.savefig(outdir / f\"bayes_factor_vs_a_total_noise_model_T7.{file_format}\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8f1e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "\n",
    "model_1 = \"model_3\"\n",
    "model_2 = \"model_1\"\n",
    "a_total = (parameters[model_1][\"a_1\"]) + parameters[model_1][\"a_ratio\"] * parameters[model_1][\"a_1\"]\n",
    "log10_bf_signal = (log_z[model_1] - log_z[model_2]) / np.log(10)\n",
    "\n",
    "tau_diff = parameters[model_1][\"tau_1\"] - parameters[model_1][\"tau_2\"]\n",
    "cval = tau_diff\n",
    "cval = parameters[model_1][\"a_ratio\"]\n",
    "vabs = np.abs(cval).max()\n",
    "\n",
    "norm = plt.Normalize(vmin=0, vmax=1)\n",
    "cmap = sns.color_palette(\"managua\", as_cmap=True)\n",
    "plt.scatter(a_total, log10_bf_signal, c=cval, cmap=cmap, marker=\"o\", s=10, norm=norm)\n",
    "cbar = plt.colorbar(label=r\"$\\rho$\")\n",
    "# cbar.ax.set_yticks([-1e3, -1e1, 0, 1e1, 1e3])\n",
    "\n",
    "plt.title(r\"$M_3, T=7, \\xi_\\text{A} > 0$ vs. $M_1, \\xi_\\text{A} > 0$\")\n",
    "# axs.set_xscale(\"log\")\n",
    "axs.set_xlabel(r\"$\\widehat{a_\\text{T}}$\")\n",
    "# axs.set_yscale(\"log\")\n",
    "axs.set_yscale(\"symlog\")\n",
    "axs.set_ylabel(r\"$\\log_{10} \\mathcal{B}$\")\n",
    "fig.savefig(outdir / f\"bayes_factor_vs_a_total_noise_model_T7_ratio.{file_format}\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3873e92-33f3-4c29-9012-13cb01112c91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes-beat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
