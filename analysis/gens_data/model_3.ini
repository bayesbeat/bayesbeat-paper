[General]
; Output directory
output = rundir/model_3_7_terms/
; Label
label = model_3_7_terms
; Path to data
datafile = ../../data/PyTotalAnalysis_2024_02_23.mat
injection = False
indices = "all"
seed = 1234
plot = True

[Model]
name = GenericAnalyticGaussianBeam
; Name of the equation to use
equation_name = General_Equation_7_Terms
; Number of terms in the ERF expansion
n_terms = 7
; Think this isn't actually used
photodiode-size = 10.2e-3
; These values are set based on Simon's measurements
; All in units of mm originally
photodiode-gap = 0.05e-3
; Beam radius
beam_radius = 3.3e-3
; Include the gap
include_gap = True
; Enforce a_1 > a_2, remove this if sampling 'a_ratio'
amplitude_constraint = False
; Assume constant noise has mean = 0
mean_constant_noise = 0.0
; Priors bounds
update_prior_bounds = priors.json
prior_bounds = {"log10_a_1": [-7, -3], "a_ratio": [0, 1], "log10_a_scale": [0, 6], "dphi": [0, 6.283185307179586], "domega": [0, 5], "tau_1": [10, 5000], "tau_2": [0, 5000], "sigma_amp_noise": [0.0, 1e-1], "sigma_constant_noise": [0.0, 0.1], "x_offset": [0.0, 1e-4]}

[Analysis]
; n-pool will be set automatically if submitting via HTCondor/Slurm
resume = True

[Sampler]
nlive = 1000
torch_dtype = "float64"
flow_proposal_class = "flowproposal"
enforce_likelihood_threshold = True
latent_prior = "flow"
constant_volume_mode = False
reset_flow = 8
flow_config = {"n_neurons": 32, "n_blocks": 6, "n_layers": 2, "linear_transform": None, "batch_norm_between_layers": True, "net": "mlp"}
training_config = {"patience": 10, "optimiser": "adam", "batch_size": 256}
reparameterisations = {"log_amplitude": {"parameters": ["log10_a_scale", "log10_a_1"]}}

[HTCondor]
request-cpus = 8
request-memory = 4GB
request-disk = 4GB
accounting-group = aluk.dev.o5.coatings.inference
accounting-group-user = michael.williams
transfer-files = True
additional-files = priors.json
